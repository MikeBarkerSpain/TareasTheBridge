{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd093959734c7fb7f2dc7760fccbd71d0356ba421f29bb59ffa607c9608db7abb2a",
   "display_name": "Python 3.7.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "93959734c7fb7f2dc7760fccbd71d0356ba421f29bb59ffa607c9608db7abb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. \n",
    "\n",
    "En el archivo \"logistic_regression_digits\" hemos visto un ejemplo multiclase. Elimina todas las imágenes y etiqueta (label) cuyo valor del label no sea 1 o 9. Es decir, elimina todos los dígitos y quédate solo con los dígitos 1 y 9.\n",
    "\n",
    "Ahora, realiza un entrenamiento con logistic regression con los nuevos datos:\n",
    "\n",
    "- ¿Se mejora la precisión del algoritmo con dos clases? ¿por qué?\n",
    "\n",
    "LogisticRegression() es una clase que tiene varios parámetros de entrada. Investiga (modifica, prueba) los argumentos y comenta si modificando algunas de ellas se mejora el porcentaje de acierto del problema (probar al menos 2 diferentes)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "# se importa el dataset y se convierte en dataframe para filtrarlo\n",
    "digits = load_digits() \n",
    "df = pd.DataFrame(data= np.c_[digits['data'], digits['target']])\n",
    "df_fil = df[(df[64]==1) | (df[64]==9)]\n",
    "dig_fil = np.array(df_fil)\n",
    "\n",
    "# se separan los datos y se entrena el modelo con ellos\n",
    "X = dig_fil[:,:-1]\n",
    "y = dig_fil[:,64]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "logisticRegr = LogisticRegression(max_iter=10000)\n",
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "score de predicción: 0.9863013698630136\nMatriz de confusión:\n [[37  0]\n [ 1 35]]\n"
     ]
    }
   ],
   "source": [
    "# predicción y análisis de resultados\n",
    "y_pred = logisticRegr.predict(X_test)\n",
    "print(\"score de predicción:\", logisticRegr.score(X_test, y_test))\n",
    "print(\"Matriz de confusión:\\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "¿Se mejora la precisión del algoritmo con dos clases? ¿por qué?\n",
    "Si, se mejora el acierto, puede ser porque al haber menos clases, sea más fácil encontrar patrones o porque estas clases son las más fáciles de reconocer. Habría que repetir el análisis para otros números a ver si en esos casos el porcentaje aumenta también."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "score de predicción: 0.9859154929577465\nMatriz de confusión:\n [[35  0]\n [ 1 35]]\n"
     ]
    }
   ],
   "source": [
    "# se importa el dataset y se convierte en dataframe para filtrarlo\n",
    "df_fil28 = df[(df[64]==2) | (df[64]==8)]\n",
    "dig_fil28 = np.array(df_fil28)\n",
    "\n",
    "# se separan los datos y se entrena el modelo con ellos\n",
    "X28 = np.array(dig_fil28[:,:-1])\n",
    "y28 = np.array(dig_fil28[:,64])\n",
    "X28_train, X28_test, y28_train,y28_test = train_test_split(X28, y28, test_size=0.20, random_state=42)\n",
    "logisticRegr28 = LogisticRegression(max_iter=10000)\n",
    "logisticRegr28.fit(X28_train, y28_train)\n",
    "\n",
    "# predicción y análisis de resultados\n",
    "y28_pred = logisticRegr28.predict(X28_test)\n",
    "print(\"score de predicción:\", logisticRegr28.score(X28_test, y28_test))\n",
    "print(\"Matriz de confusión:\\n\", metrics.confusion_matrix(y28_test, y28_pred))"
   ]
  },
  {
   "source": [
    "Al hacer la prueba con dos números distintos, el porcentaje sigue siendo igual de alto, por lo que no se puede atribuir a que los número s1 y 9 tengan patrones más reconocibles."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "score de predicción: 1.0\nMatriz de confusión:\n [[39  0  0]\n [ 0 32  0]\n [ 0  0 35]]\nscore de predicción: 1.0\nMatriz de confusión:\n [[177   0   0]\n [  0 179   0]\n [  0   0 174]]\n"
     ]
    }
   ],
   "source": [
    "# se importa el dataset y se convierte en dataframe para filtrarlo\n",
    "df_fil3 = df[(df[64]==2) | (df[64]==8)| (df[64]==7)]\n",
    "dig_fil3 = np.array(df_fil3)\n",
    "\n",
    "# se separan los datos y se entrena el modelo con ellos\n",
    "X3 = np.array(dig_fil3[:,:-1])\n",
    "y3 = np.array(dig_fil3[:,64])\n",
    "X3_train, X3_test, y3_train,y3_test = train_test_split(X3, y3, test_size=0.20, random_state=42)\n",
    "logisticRegr3 = LogisticRegression(max_iter=10000)\n",
    "logisticRegr3.fit(X3_train, y3_train)\n",
    "\n",
    "# predicción y análisis de resultados\n",
    "y3_pred = logisticRegr3.predict(X3_test)\n",
    "print(\"score de predicción:\", logisticRegr3.score(X3_test, y3_test))\n",
    "print(\"Matriz de confusión:\\n\", metrics.confusion_matrix(y3_test, y3_pred))\n",
    "\n",
    "#predicción total\n",
    "y3_pred_tot = logisticRegr3.predict(X3)\n",
    "print(\"score de predicción:\", logisticRegr3.score(X3, y3))\n",
    "print(\"Matriz de confusión:\\n\", metrics.confusion_matrix(y3, y3_pred_tot))\n",
    "\n"
   ]
  },
  {
   "source": [
    "Al hacer la prueba con tres clases, el resultado es aun mejor que con dos, por lo que no se puede concluir que la mejora se deba a que haya menos clases."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "score de predicción: 0.9722222222222222\n",
      "Matriz de confusión:\n",
      " [[33  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 33  0  1  0  0  0  0]\n",
      " [ 0  1  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  1  0  0 44  1  0  0  1]\n",
      " [ 0  0  0  0  0  1 34  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 33  0  0]\n",
      " [ 0  0  0  0  0  1  0  0 29  0]\n",
      " [ 0  0  0  1  0  0  0  0  1 38]]\n",
      "score de predicción: 0.9944351697273233\n",
      "Matriz de confusión:\n",
      " [[178   0   0   0   0   0   0   0   0   0]\n",
      " [  0 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0 177   0   0   0   0   0   0   0]\n",
      " [  0   0   0 182   0   1   0   0   0   0]\n",
      " [  0   1   0   0 180   0   0   0   0   0]\n",
      " [  0   0   1   0   0 179   1   0   0   1]\n",
      " [  0   0   0   0   0   1 180   0   0   0]\n",
      " [  0   0   0   0   0   1   0 178   0   0]\n",
      " [  0   0   0   0   0   1   0   0 173   0]\n",
      " [  0   0   0   1   0   0   0   0   1 178]]\n",
      "score de predicción: 0.9944351697273233\n",
      "Matriz de confusión:\n",
      " [[178   0   0   0   0   0   0   0   0   0]\n",
      " [  0 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0 177   0   0   0   0   0   0   0]\n",
      " [  0   0   0 182   0   1   0   0   0   0]\n",
      " [  0   1   0   0 180   0   0   0   0   0]\n",
      " [  0   0   1   0   0 179   1   0   0   1]\n",
      " [  0   0   0   0   0   1 180   0   0   0]\n",
      " [  0   0   0   0   0   1   0 178   0   0]\n",
      " [  0   0   0   0   0   1   0   0 173   0]\n",
      " [  0   0   0   1   0   0   0   0   1 178]]\n"
     ]
    }
   ],
   "source": [
    "# se separan los datos y se entrena el modelo con ellos\n",
    "X10 = digits.data\n",
    "y10 = digits.target\n",
    "X10_train, X10_test, y10_train,y10_test = train_test_split(X10, y10, test_size=0.20, random_state=42)\n",
    "logisticRegr10 = LogisticRegression(max_iter=10000)\n",
    "logisticRegr10.fit(X10_train, y10_train)\n",
    "\n",
    "# predicción y análisis de resultados\n",
    "y10_pred = logisticRegr10.predict(X10_test)\n",
    "print(\"score de predicción:\", logisticRegr10.score(X10_test, y10_test))\n",
    "print(\"Matriz de confusión:\\n\", metrics.confusion_matrix(y10_test, y10_pred))\n",
    "\n",
    "#predicción total\n",
    "y10_pred_tot = logisticRegr10.predict(X10)\n",
    "print(\"score de predicción:\", logisticRegr10.score(X10, y10))\n",
    "print(\"Matriz de confusión:\\n\", metrics.confusion_matrix(y10, y10_pred_tot))\n",
    "\n",
    "# predicción total mejorada\n",
    "logisticRegr10bis = LogisticRegression(max_iter=10000, tol=1e-10, C=0.1, class_weight='balanced', solver='lbfgs', n_jobs=-1)\n",
    "logisticRegr10bis.fit(X10_train, y10_train)\n",
    "y10bis_pred_tot = logisticRegr10bis.predict(X10)\n",
    "print(\"score de predicción:\", logisticRegr10bis.score(X10, y10))\n",
    "print(\"Matriz de confusión:\\n\", metrics.confusion_matrix(y10, y10bis_pred_tot))\n"
   ]
  },
  {
   "source": [
    "LogisticRegression() es una clase que tiene varios parámetros de entrada. Investiga (modifica, prueba) los argumentos y comenta si modificando algunas de ellas se mejora el porcentaje de acierto del problema (probar al menos 2 diferentes)\n",
    "\n",
    "se han modificado varios argumentos de la función sin que ello haya significado una mejora en el resultado del modelo de regressión."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
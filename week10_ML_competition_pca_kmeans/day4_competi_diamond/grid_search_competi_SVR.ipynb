{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "93959734c7fb7f2dc7760fccbd71d0356ba421f29bb59ffa607c9608db7abb2a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is GridSearch?\n",
    "GridSearch is an optimization tool that we use when tuning hyperparameters. We define the grid of parameters that we want to search through, and we select the best combination of parameters for our data.\n",
    "\n",
    "https://towardsdatascience.com/gridsearch-the-ultimate-machine-learning-tool-6cd5fb93d07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The “Grid” in GridSearch\n",
    "\n",
    "![grid](grid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: One way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# se generan valores numéricos con todas las columnas\n",
    "# cut (distribución logaritmica 'manual') -> Ideal=100, Premium=95, Very Good= 85, Good=70 y Fair=50\n",
    "def cut_to_number (cut, log_list) :\n",
    "    if cut == 'Ideal':\n",
    "        return log_list[0]\n",
    "    elif cut == 'Premium':\n",
    "        return log_list[1]\n",
    "    elif cut == 'Very Good':\n",
    "        return log_list[2]\n",
    "    elif cut == 'Good':\n",
    "        return log_list[3]\n",
    "    else:\n",
    "        return log_list[4]\n",
    "\n",
    "# color (ídem) -> D=100, E=95, F=85, G=70 y H=50\n",
    "def color_to_number (color, log_list) :\n",
    "    if color == 'D':\n",
    "        return log_list[0]\n",
    "    elif color == 'E':\n",
    "        return log_list[1]\n",
    "    elif color == 'F':\n",
    "        return log_list[2]\n",
    "    elif color == 'G':\n",
    "        return log_list[3]\n",
    "    else:\n",
    "        return log_list[4]\n",
    "\n",
    "# clarity (ídem) -> IF=100, VVS1=98, VVS2=94, VS1=88, VS2=80, SI1=69, SI2=55 y  I1=37\n",
    "def clarity_to_number (clarity, log_list) :\n",
    "    if clarity == 'IF':\n",
    "        return log_list[0]\n",
    "    elif clarity == 'VVS1':\n",
    "        return log_list[1]\n",
    "    elif clarity == 'VVS2':\n",
    "        return log_list[2]\n",
    "    elif clarity == 'VS1':\n",
    "        return log_list[3]\n",
    "    elif clarity == 'VS2':\n",
    "        return log_list[4]\n",
    "    elif clarity == 'SI1':\n",
    "        return log_list[5]\n",
    "    elif clarity == 'SI2':\n",
    "        return log_list[6]\n",
    "    else:\n",
    "        return log_list[7]\n",
    "\n",
    "log_list5 = [100, 95, 85, 70, 50]\n",
    "log_list8 = [100, 98, 94, 88, 80,69, 55, 37]\n",
    "\n",
    "\n",
    "### Para que funcione necesitas bajarte los archivos de datos de Kaggle \n",
    "df = pd.read_csv(\"diamonds_train.csv\", index_col=0)\n",
    "df['cut'] = df['cut'].apply(lambda x: cut_to_number(x, log_list5))\n",
    "df['color'] = df['color'].apply(lambda x: color_to_number(x, log_list5))\n",
    "df['clarity'] = df['clarity'].apply(lambda x: clarity_to_number(x, log_list8))\n",
    "\n",
    "# 1. Definir X e y\n",
    "X = np.array(df.drop(columns=['price'])) # se elige toda la tabla menos el precio\n",
    "#X = np.array(df[['carat','cut','color','clarity','depth','table']]) # se selecciona las columnas más importantes\n",
    "y = np.array(df[\"price\"])\n",
    "\n",
    "# 2. Dividir X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle= True, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "[CV 1/2; 1/50] START C=5, coef0=0.0, degree=3, kernel=poly......................\n",
      "[CV 1/2; 1/50] END C=5, coef0=0.0, degree=3, kernel=poly;, score=0.023 total time=  11.6s\n",
      "[CV 2/2; 1/50] START C=5, coef0=0.0, degree=3, kernel=poly......................\n",
      "[CV 2/2; 1/50] END C=5, coef0=0.0, degree=3, kernel=poly;, score=0.030 total time=  11.7s\n",
      "[CV 1/2; 2/50] START C=5, coef0=0.0, degree=4, kernel=poly......................\n",
      "[CV 1/2; 2/50] END C=5, coef0=0.0, degree=4, kernel=poly;, score=0.193 total time=  11.7s\n",
      "[CV 2/2; 2/50] START C=5, coef0=0.0, degree=4, kernel=poly......................\n",
      "[CV 2/2; 2/50] END C=5, coef0=0.0, degree=4, kernel=poly;, score=0.201 total time=  11.7s\n",
      "[CV 1/2; 3/50] START C=5, coef0=0.0, degree=5, kernel=poly......................\n",
      "[CV 1/2; 3/50] END C=5, coef0=0.0, degree=5, kernel=poly;, score=0.443 total time=  11.6s\n",
      "[CV 2/2; 3/50] START C=5, coef0=0.0, degree=5, kernel=poly......................\n",
      "[CV 2/2; 3/50] END C=5, coef0=0.0, degree=5, kernel=poly;, score=0.454 total time=  11.6s\n",
      "[CV 1/2; 4/50] START C=5, coef0=0.0, degree=6, kernel=poly......................\n",
      "[CV 1/2; 4/50] END C=5, coef0=0.0, degree=6, kernel=poly;, score=0.621 total time=  11.6s\n",
      "[CV 2/2; 4/50] START C=5, coef0=0.0, degree=6, kernel=poly......................\n",
      "[CV 2/2; 4/50] END C=5, coef0=0.0, degree=6, kernel=poly;, score=0.627 total time=  11.6s\n",
      "[CV 1/2; 5/50] START C=5, coef0=0.0, degree=7, kernel=poly......................\n",
      "[CV 1/2; 5/50] END C=5, coef0=0.0, degree=7, kernel=poly;, score=0.692 total time=  11.5s\n",
      "[CV 2/2; 5/50] START C=5, coef0=0.0, degree=7, kernel=poly......................\n",
      "[CV 2/2; 5/50] END C=5, coef0=0.0, degree=7, kernel=poly;, score=0.689 total time=  11.6s\n",
      "[CV 1/2; 6/50] START C=5, coef0=0.1, degree=3, kernel=poly......................\n",
      "[CV 1/2; 6/50] END C=5, coef0=0.1, degree=3, kernel=poly;, score=0.032 total time=  11.7s\n",
      "[CV 2/2; 6/50] START C=5, coef0=0.1, degree=3, kernel=poly......................\n",
      "[CV 2/2; 6/50] END C=5, coef0=0.1, degree=3, kernel=poly;, score=0.039 total time=  11.4s\n",
      "[CV 1/2; 7/50] START C=5, coef0=0.1, degree=4, kernel=poly......................\n",
      "[CV 1/2; 7/50] END C=5, coef0=0.1, degree=4, kernel=poly;, score=0.224 total time=  11.6s\n",
      "[CV 2/2; 7/50] START C=5, coef0=0.1, degree=4, kernel=poly......................\n",
      "[CV 2/2; 7/50] END C=5, coef0=0.1, degree=4, kernel=poly;, score=0.232 total time=  11.9s\n",
      "[CV 1/2; 8/50] START C=5, coef0=0.1, degree=5, kernel=poly......................\n",
      "[CV 1/2; 8/50] END C=5, coef0=0.1, degree=5, kernel=poly;, score=0.484 total time=  11.5s\n",
      "[CV 2/2; 8/50] START C=5, coef0=0.1, degree=5, kernel=poly......................\n",
      "[CV 2/2; 8/50] END C=5, coef0=0.1, degree=5, kernel=poly;, score=0.494 total time=  11.5s\n",
      "[CV 1/2; 9/50] START C=5, coef0=0.1, degree=6, kernel=poly......................\n",
      "[CV 1/2; 9/50] END C=5, coef0=0.1, degree=6, kernel=poly;, score=0.652 total time=  11.0s\n",
      "[CV 2/2; 9/50] START C=5, coef0=0.1, degree=6, kernel=poly......................\n",
      "[CV 2/2; 9/50] END C=5, coef0=0.1, degree=6, kernel=poly;, score=0.659 total time=  11.0s\n",
      "[CV 1/2; 10/50] START C=5, coef0=0.1, degree=7, kernel=poly.....................\n",
      "[CV 1/2; 10/50] END C=5, coef0=0.1, degree=7, kernel=poly;, score=0.713 total time=  11.2s\n",
      "[CV 2/2; 10/50] START C=5, coef0=0.1, degree=7, kernel=poly.....................\n",
      "[CV 2/2; 10/50] END C=5, coef0=0.1, degree=7, kernel=poly;, score=0.710 total time=  11.2s\n",
      "[CV 1/2; 11/50] START C=5, coef0=0.5, degree=3, kernel=poly.....................\n",
      "[CV 1/2; 11/50] END C=5, coef0=0.5, degree=3, kernel=poly;, score=0.069 total time=  11.2s\n",
      "[CV 2/2; 11/50] START C=5, coef0=0.5, degree=3, kernel=poly.....................\n",
      "[CV 2/2; 11/50] END C=5, coef0=0.5, degree=3, kernel=poly;, score=0.076 total time=  11.4s\n",
      "[CV 1/2; 12/50] START C=5, coef0=0.5, degree=4, kernel=poly.....................\n",
      "[CV 1/2; 12/50] END C=5, coef0=0.5, degree=4, kernel=poly;, score=0.351 total time=  11.6s\n",
      "[CV 2/2; 12/50] START C=5, coef0=0.5, degree=4, kernel=poly.....................\n",
      "[CV 2/2; 12/50] END C=5, coef0=0.5, degree=4, kernel=poly;, score=0.359 total time=  11.9s\n",
      "[CV 1/2; 13/50] START C=5, coef0=0.5, degree=5, kernel=poly.....................\n",
      "[CV 1/2; 13/50] END C=5, coef0=0.5, degree=5, kernel=poly;, score=0.619 total time=  10.9s\n",
      "[CV 2/2; 13/50] START C=5, coef0=0.5, degree=5, kernel=poly.....................\n",
      "[CV 2/2; 13/50] END C=5, coef0=0.5, degree=5, kernel=poly;, score=0.625 total time=  10.8s\n",
      "[CV 1/2; 14/50] START C=5, coef0=0.5, degree=6, kernel=poly.....................\n",
      "[CV 1/2; 14/50] END C=5, coef0=0.5, degree=6, kernel=poly;, score=0.732 total time=  11.0s\n",
      "[CV 2/2; 14/50] START C=5, coef0=0.5, degree=6, kernel=poly.....................\n",
      "[CV 2/2; 14/50] END C=5, coef0=0.5, degree=6, kernel=poly;, score=0.731 total time=  11.1s\n",
      "[CV 1/2; 15/50] START C=5, coef0=0.5, degree=7, kernel=poly.....................\n",
      "[CV 1/2; 15/50] END C=5, coef0=0.5, degree=7, kernel=poly;, score=0.771 total time=  11.4s\n",
      "[CV 2/2; 15/50] START C=5, coef0=0.5, degree=7, kernel=poly.....................\n",
      "[CV 2/2; 15/50] END C=5, coef0=0.5, degree=7, kernel=poly;, score=0.769 total time=  11.8s\n",
      "[CV 1/2; 16/50] START C=5, coef0=1, degree=3, kernel=poly.......................\n",
      "[CV 1/2; 16/50] END C=5, coef0=1, degree=3, kernel=poly;, score=0.121 total time=  11.5s\n",
      "[CV 2/2; 16/50] START C=5, coef0=1, degree=3, kernel=poly.......................\n",
      "[CV 2/2; 16/50] END C=5, coef0=1, degree=3, kernel=poly;, score=0.126 total time=  11.2s\n",
      "[CV 1/2; 17/50] START C=5, coef0=1, degree=4, kernel=poly.......................\n",
      "[CV 1/2; 17/50] END C=5, coef0=1, degree=4, kernel=poly;, score=0.485 total time=  11.4s\n",
      "[CV 2/2; 17/50] START C=5, coef0=1, degree=4, kernel=poly.......................\n",
      "[CV 2/2; 17/50] END C=5, coef0=1, degree=4, kernel=poly;, score=0.492 total time=  11.0s\n",
      "[CV 1/2; 18/50] START C=5, coef0=1, degree=5, kernel=poly.......................\n",
      "[CV 1/2; 18/50] END C=5, coef0=1, degree=5, kernel=poly;, score=0.708 total time=  10.7s\n",
      "[CV 2/2; 18/50] START C=5, coef0=1, degree=5, kernel=poly.......................\n",
      "[CV 2/2; 18/50] END C=5, coef0=1, degree=5, kernel=poly;, score=0.712 total time=  11.0s\n",
      "[CV 1/2; 19/50] START C=5, coef0=1, degree=6, kernel=poly.......................\n",
      "[CV 1/2; 19/50] END C=5, coef0=1, degree=6, kernel=poly;, score=0.775 total time=  11.1s\n",
      "[CV 2/2; 19/50] START C=5, coef0=1, degree=6, kernel=poly.......................\n",
      "[CV 2/2; 19/50] END C=5, coef0=1, degree=6, kernel=poly;, score=0.775 total time=  11.4s\n",
      "[CV 1/2; 20/50] START C=5, coef0=1, degree=7, kernel=poly.......................\n",
      "[CV 1/2; 20/50] END C=5, coef0=1, degree=7, kernel=poly;, score=0.825 total time=  12.0s\n",
      "[CV 2/2; 20/50] START C=5, coef0=1, degree=7, kernel=poly.......................\n",
      "[CV 2/2; 20/50] END C=5, coef0=1, degree=7, kernel=poly;, score=0.829 total time=  12.0s\n",
      "[CV 1/2; 21/50] START C=5, coef0=10, degree=3, kernel=poly......................\n",
      "[CV 1/2; 21/50] END C=5, coef0=10, degree=3, kernel=poly;, score=0.689 total time=  10.7s\n",
      "[CV 2/2; 21/50] START C=5, coef0=10, degree=3, kernel=poly......................\n",
      "[CV 2/2; 21/50] END C=5, coef0=10, degree=3, kernel=poly;, score=0.696 total time=  10.8s\n",
      "[CV 1/2; 22/50] START C=5, coef0=10, degree=4, kernel=poly......................\n",
      "[CV 1/2; 22/50] END C=5, coef0=10, degree=4, kernel=poly;, score=0.826 total time=  11.6s\n",
      "[CV 2/2; 22/50] START C=5, coef0=10, degree=4, kernel=poly......................\n",
      "[CV 2/2; 22/50] END C=5, coef0=10, degree=4, kernel=poly;, score=0.830 total time=  11.6s\n",
      "[CV 1/2; 23/50] START C=5, coef0=10, degree=5, kernel=poly......................\n",
      "[CV 1/2; 23/50] END C=5, coef0=10, degree=5, kernel=poly;, score=0.937 total time=  28.6s\n",
      "[CV 2/2; 23/50] START C=5, coef0=10, degree=5, kernel=poly......................\n",
      "[CV 2/2; 23/50] END C=5, coef0=10, degree=5, kernel=poly;, score=0.936 total time=  26.7s\n",
      "[CV 1/2; 24/50] START C=5, coef0=10, degree=6, kernel=poly......................\n",
      "[CV 1/2; 24/50] END C=5, coef0=10, degree=6, kernel=poly;, score=0.956 total time= 2.8min\n",
      "[CV 2/2; 24/50] START C=5, coef0=10, degree=6, kernel=poly......................\n",
      "[CV 2/2; 24/50] END C=5, coef0=10, degree=6, kernel=poly;, score=0.944 total time= 3.1min\n",
      "[CV 1/2; 25/50] START C=5, coef0=10, degree=7, kernel=poly......................\n",
      "[CV 1/2; 25/50] END C=5, coef0=10, degree=7, kernel=poly;, score=0.786 total time=23.2min\n",
      "[CV 2/2; 25/50] START C=5, coef0=10, degree=7, kernel=poly......................\n",
      "[CV 2/2; 25/50] END C=5, coef0=10, degree=7, kernel=poly;, score=0.948 total time=16.4min\n",
      "[CV 1/2; 26/50] START C=7, coef0=0.0, degree=3, kernel=poly.....................\n",
      "[CV 1/2; 26/50] END C=7, coef0=0.0, degree=3, kernel=poly;, score=0.060 total time=  10.3s\n",
      "[CV 2/2; 26/50] START C=7, coef0=0.0, degree=3, kernel=poly.....................\n",
      "[CV 2/2; 26/50] END C=7, coef0=0.0, degree=3, kernel=poly;, score=0.067 total time=  10.4s\n",
      "[CV 1/2; 27/50] START C=7, coef0=0.0, degree=4, kernel=poly.....................\n",
      "[CV 1/2; 27/50] END C=7, coef0=0.0, degree=4, kernel=poly;, score=0.274 total time=  10.5s\n",
      "[CV 2/2; 27/50] START C=7, coef0=0.0, degree=4, kernel=poly.....................\n",
      "[CV 2/2; 27/50] END C=7, coef0=0.0, degree=4, kernel=poly;, score=0.283 total time=  10.7s\n",
      "[CV 1/2; 28/50] START C=7, coef0=0.0, degree=5, kernel=poly.....................\n",
      "[CV 1/2; 28/50] END C=7, coef0=0.0, degree=5, kernel=poly;, score=0.518 total time=  10.5s\n",
      "[CV 2/2; 28/50] START C=7, coef0=0.0, degree=5, kernel=poly.....................\n",
      "[CV 2/2; 28/50] END C=7, coef0=0.0, degree=5, kernel=poly;, score=0.526 total time=  10.6s\n",
      "[CV 1/2; 29/50] START C=7, coef0=0.0, degree=6, kernel=poly.....................\n",
      "[CV 1/2; 29/50] END C=7, coef0=0.0, degree=6, kernel=poly;, score=0.662 total time=  10.5s\n",
      "[CV 2/2; 29/50] START C=7, coef0=0.0, degree=6, kernel=poly.....................\n",
      "[CV 2/2; 29/50] END C=7, coef0=0.0, degree=6, kernel=poly;, score=0.667 total time=  10.4s\n",
      "[CV 1/2; 30/50] START C=7, coef0=0.0, degree=7, kernel=poly.....................\n",
      "[CV 1/2; 30/50] END C=7, coef0=0.0, degree=7, kernel=poly;, score=0.710 total time=  10.8s\n",
      "[CV 2/2; 30/50] START C=7, coef0=0.0, degree=7, kernel=poly.....................\n",
      "[CV 2/2; 30/50] END C=7, coef0=0.0, degree=7, kernel=poly;, score=0.706 total time=  10.7s\n",
      "[CV 1/2; 31/50] START C=7, coef0=0.1, degree=3, kernel=poly.....................\n",
      "[CV 1/2; 31/50] END C=7, coef0=0.1, degree=3, kernel=poly;, score=0.072 total time=  11.0s\n",
      "[CV 2/2; 31/50] START C=7, coef0=0.1, degree=3, kernel=poly.....................\n",
      "[CV 2/2; 31/50] END C=7, coef0=0.1, degree=3, kernel=poly;, score=0.079 total time=  10.7s\n",
      "[CV 1/2; 32/50] START C=7, coef0=0.1, degree=4, kernel=poly.....................\n",
      "[CV 1/2; 32/50] END C=7, coef0=0.1, degree=4, kernel=poly;, score=0.310 total time=  10.8s\n",
      "[CV 2/2; 32/50] START C=7, coef0=0.1, degree=4, kernel=poly.....................\n",
      "[CV 2/2; 32/50] END C=7, coef0=0.1, degree=4, kernel=poly;, score=0.320 total time=  10.7s\n",
      "[CV 1/2; 33/50] START C=7, coef0=0.1, degree=5, kernel=poly.....................\n",
      "[CV 1/2; 33/50] END C=7, coef0=0.1, degree=5, kernel=poly;, score=0.557 total time=  10.3s\n",
      "[CV 2/2; 33/50] START C=7, coef0=0.1, degree=5, kernel=poly.....................\n",
      "[CV 2/2; 33/50] END C=7, coef0=0.1, degree=5, kernel=poly;, score=0.564 total time=  10.2s\n",
      "[CV 1/2; 34/50] START C=7, coef0=0.1, degree=6, kernel=poly.....................\n",
      "[CV 1/2; 34/50] END C=7, coef0=0.1, degree=6, kernel=poly;, score=0.688 total time=  10.2s\n",
      "[CV 2/2; 34/50] START C=7, coef0=0.1, degree=6, kernel=poly.....................\n",
      "[CV 2/2; 34/50] END C=7, coef0=0.1, degree=6, kernel=poly;, score=0.690 total time=  10.1s\n",
      "[CV 1/2; 35/50] START C=7, coef0=0.1, degree=7, kernel=poly.....................\n",
      "[CV 1/2; 35/50] END C=7, coef0=0.1, degree=7, kernel=poly;, score=0.729 total time=  10.4s\n",
      "[CV 2/2; 35/50] START C=7, coef0=0.1, degree=7, kernel=poly.....................\n",
      "[CV 2/2; 35/50] END C=7, coef0=0.1, degree=7, kernel=poly;, score=0.726 total time=  10.3s\n",
      "[CV 1/2; 36/50] START C=7, coef0=0.5, degree=3, kernel=poly.....................\n",
      "[CV 1/2; 36/50] END C=7, coef0=0.5, degree=3, kernel=poly;, score=0.120 total time=  10.5s\n",
      "[CV 2/2; 36/50] START C=7, coef0=0.5, degree=3, kernel=poly.....................\n",
      "[CV 2/2; 36/50] END C=7, coef0=0.5, degree=3, kernel=poly;, score=0.126 total time=  10.3s\n",
      "[CV 1/2; 37/50] START C=7, coef0=0.5, degree=4, kernel=poly.....................\n",
      "[CV 1/2; 37/50] END C=7, coef0=0.5, degree=4, kernel=poly;, score=0.440 total time=  10.2s\n",
      "[CV 2/2; 37/50] START C=7, coef0=0.5, degree=4, kernel=poly.....................\n",
      "[CV 2/2; 37/50] END C=7, coef0=0.5, degree=4, kernel=poly;, score=0.448 total time=  10.2s\n",
      "[CV 1/2; 38/50] START C=7, coef0=0.5, degree=5, kernel=poly.....................\n",
      "[CV 1/2; 38/50] END C=7, coef0=0.5, degree=5, kernel=poly;, score=0.666 total time=  10.1s\n",
      "[CV 2/2; 38/50] START C=7, coef0=0.5, degree=5, kernel=poly.....................\n",
      "[CV 2/2; 38/50] END C=7, coef0=0.5, degree=5, kernel=poly;, score=0.674 total time=  10.1s\n",
      "[CV 1/2; 39/50] START C=7, coef0=0.5, degree=6, kernel=poly.....................\n",
      "[CV 1/2; 39/50] END C=7, coef0=0.5, degree=6, kernel=poly;, score=0.748 total time=  10.2s\n",
      "[CV 2/2; 39/50] START C=7, coef0=0.5, degree=6, kernel=poly.....................\n",
      "[CV 2/2; 39/50] END C=7, coef0=0.5, degree=6, kernel=poly;, score=0.746 total time=  10.4s\n",
      "[CV 1/2; 40/50] START C=7, coef0=0.5, degree=7, kernel=poly.....................\n",
      "[CV 1/2; 40/50] END C=7, coef0=0.5, degree=7, kernel=poly;, score=0.786 total time=  10.6s\n",
      "[CV 2/2; 40/50] START C=7, coef0=0.5, degree=7, kernel=poly.....................\n",
      "[CV 2/2; 40/50] END C=7, coef0=0.5, degree=7, kernel=poly;, score=0.786 total time=  10.9s\n",
      "[CV 1/2; 41/50] START C=7, coef0=1, degree=3, kernel=poly.......................\n",
      "[CV 1/2; 41/50] END C=7, coef0=1, degree=3, kernel=poly;, score=0.188 total time=  10.4s\n",
      "[CV 2/2; 41/50] START C=7, coef0=1, degree=3, kernel=poly.......................\n",
      "[CV 2/2; 41/50] END C=7, coef0=1, degree=3, kernel=poly;, score=0.193 total time=  10.4s\n",
      "[CV 1/2; 42/50] START C=7, coef0=1, degree=4, kernel=poly.......................\n",
      "[CV 1/2; 42/50] END C=7, coef0=1, degree=4, kernel=poly;, score=0.558 total time=  10.1s\n",
      "[CV 2/2; 42/50] START C=7, coef0=1, degree=4, kernel=poly.......................\n",
      "[CV 2/2; 42/50] END C=7, coef0=1, degree=4, kernel=poly;, score=0.566 total time=  10.3s\n",
      "[CV 1/2; 43/50] START C=7, coef0=1, degree=5, kernel=poly.......................\n",
      "[CV 1/2; 43/50] END C=7, coef0=1, degree=5, kernel=poly;, score=0.734 total time=  10.2s\n",
      "[CV 2/2; 43/50] START C=7, coef0=1, degree=5, kernel=poly.......................\n",
      "[CV 2/2; 43/50] END C=7, coef0=1, degree=5, kernel=poly;, score=0.736 total time=  10.3s\n",
      "[CV 1/2; 44/50] START C=7, coef0=1, degree=6, kernel=poly.......................\n",
      "[CV 1/2; 44/50] END C=7, coef0=1, degree=6, kernel=poly;, score=0.787 total time=  10.7s\n",
      "[CV 2/2; 44/50] START C=7, coef0=1, degree=6, kernel=poly.......................\n",
      "[CV 2/2; 44/50] END C=7, coef0=1, degree=6, kernel=poly;, score=0.787 total time=  10.7s\n",
      "[CV 1/2; 45/50] START C=7, coef0=1, degree=7, kernel=poly.......................\n",
      "[CV 1/2; 45/50] END C=7, coef0=1, degree=7, kernel=poly;, score=0.844 total time=  11.5s\n",
      "[CV 2/2; 45/50] START C=7, coef0=1, degree=7, kernel=poly.......................\n",
      "[CV 2/2; 45/50] END C=7, coef0=1, degree=7, kernel=poly;, score=0.848 total time=  11.5s\n",
      "[CV 1/2; 46/50] START C=7, coef0=10, degree=3, kernel=poly......................\n",
      "[CV 1/2; 46/50] END C=7, coef0=10, degree=3, kernel=poly;, score=0.720 total time=  10.0s\n",
      "[CV 2/2; 46/50] START C=7, coef0=10, degree=3, kernel=poly......................\n",
      "[CV 2/2; 46/50] END C=7, coef0=10, degree=3, kernel=poly;, score=0.727 total time=  10.1s\n",
      "[CV 1/2; 47/50] START C=7, coef0=10, degree=4, kernel=poly......................\n",
      "[CV 1/2; 47/50] END C=7, coef0=10, degree=4, kernel=poly;, score=0.840 total time=  11.2s\n",
      "[CV 2/2; 47/50] START C=7, coef0=10, degree=4, kernel=poly......................\n",
      "[CV 2/2; 47/50] END C=7, coef0=10, degree=4, kernel=poly;, score=0.843 total time=  11.4s\n",
      "[CV 1/2; 48/50] START C=7, coef0=10, degree=5, kernel=poly......................\n",
      "[CV 1/2; 48/50] END C=7, coef0=10, degree=5, kernel=poly;, score=0.941 total time=  37.1s\n",
      "[CV 2/2; 48/50] START C=7, coef0=10, degree=5, kernel=poly......................\n",
      "[CV 2/2; 48/50] END C=7, coef0=10, degree=5, kernel=poly;, score=0.939 total time=  32.9s\n",
      "[CV 1/2; 49/50] START C=7, coef0=10, degree=6, kernel=poly......................\n",
      "[CV 1/2; 49/50] END C=7, coef0=10, degree=6, kernel=poly;, score=0.950 total time= 3.4min\n",
      "[CV 2/2; 49/50] START C=7, coef0=10, degree=6, kernel=poly......................\n",
      "[CV 2/2; 49/50] END C=7, coef0=10, degree=6, kernel=poly;, score=0.944 total time= 2.9min\n",
      "[CV 1/2; 50/50] START C=7, coef0=10, degree=7, kernel=poly......................\n",
      "[CV 1/2; 50/50] END C=7, coef0=10, degree=7, kernel=poly;, score=0.773 total time=21.8min\n",
      "[CV 2/2; 50/50] START C=7, coef0=10, degree=7, kernel=poly......................\n",
      "[CV 2/2; 50/50] END C=7, coef0=10, degree=7, kernel=poly;, score=0.952 total time=19.4min\n",
      "clf.best_stimator_ SVR(C=5, coef0=10, degree=6, kernel='poly')\n",
      "clf.best_params_ {'C': 5, 'coef0': 10, 'degree': 6, 'kernel': 'poly'}\n",
      "clf.best_score 0.9500892082043215\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 'kernel':('linear', 'poly', 'rbf', 'sigmoid'), \n",
    "\n",
    "parameters = {\n",
    "    'kernel': ['poly'], #, , 'rbf', 'sigmoid'\n",
    "    'C':[5,7],\n",
    "    'degree': [3,4,5,6,7],\n",
    "    'coef0': [ 0., 0.1, 0.5, 1, 10]\n",
    "    }\n",
    "\n",
    "svr = svm.SVR()\n",
    "\n",
    "clf = GridSearchCV(estimator=svr, param_grid=parameters, verbose=10, cv=2)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"clf.best_stimator_\", clf.best_estimator_)\n",
    "print(\"clf.best_params_\", clf.best_params_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicciones test:\n [7756.32463564 3221.9718324   467.73726891 ...  485.95906353 5450.30842891\n 2208.27777684]\nscore (RMSE) de las predicciones: 876.0669645565762\n"
     ]
    }
   ],
   "source": [
    "# 5. Predecir con el modelo ya entrenado con X_test\n",
    "predictions = clf.predict(X_test)\n",
    "print('predicciones test:\\n', predictions)\n",
    "\n",
    "# 6. Sacar métricas, valorar el modelo; en la competición se va a evaluar con la métrica de RMSE.\n",
    "print('score (RMSE) de las predicciones:', np.sqrt(mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9118.731061899869"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"diamonds_test.csv\", index_col=0)\n",
    "df_test['cut'] = df_test['cut'].apply(lambda x: cut_to_number(x, log_list5))\n",
    "df_test['color'] = df_test['color'].apply(lambda x: color_to_number(x, log_list5))\n",
    "df_test['clarity'] = df_test['clarity'].apply(lambda x: clarity_to_number(x,log_list8))\n",
    "\n",
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "#X_pred = np.array(df_test[['carat','cut','color','clarity','depth','table']]) #\n",
    "#X_pred = np.array(df_test.drop(columns=['depth','table'])) # pruebas con las tabla completa\n",
    "X_pred = np.array(df_test) # pruebas con las tabla completa\n",
    "y_sample = sample['price']\n",
    "X_pred.shape\n",
    "#y_sample.shape\n",
    "\n",
    "# líneas para el non-linear regression model\n",
    "#X_pred = polinominal_model.transform(X_pred)\n",
    "predictions_submit = clf.predict(X_pred)\n",
    "\n",
    "# líneas para todos los demás\n",
    "#predictions_submit = model.predict(X_pred)\n",
    "predictions_submit\n",
    "\n",
    "# control de error\n",
    "np.sqrt(mean_squared_error(y_sample, predictions_submit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9118.731061899869\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"diamonds_test.csv\", index_col=0)\n",
    "df_test['cut'] = df_test['cut'].apply(lambda x: cut_to_number(x, log_list5))\n",
    "df_test['color'] = df_test['color'].apply(lambda x: color_to_number(x, log_list5))\n",
    "df_test['clarity'] = df_test['clarity'].apply(lambda x: clarity_to_number(x,log_list8))\n",
    "\n",
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "#X_pred = np.array(df_test[['carat','cut','color','clarity','depth','table']]) #\n",
    "#X_pred = np.array(df_test.drop(columns=['depth','table'])) # pruebas con las tabla completa\n",
    "X_pred = np.array(df_test) # pruebas con las tabla completa\n",
    "y_sample = sample['price']\n",
    "# líneas para el non-linear regression model\n",
    "#X_pred = polinominal_model.transform(X_pred)\n",
    "predictions_submit = clf.predict(X_pred)\n",
    "\n",
    "# líneas para todos los demás\n",
    "#predictions_submit = model.predict(X_pred)\n",
    "predictions_submit\n",
    "\n",
    "# control de error\n",
    "print(np.sqrt(mean_squared_error(y_sample, predictions_submit)))\n",
    "submission = pd.DataFrame({\"id\": range(len(predictions_submit)), \"price\": predictions_submit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You're ready to submit!\n"
     ]
    }
   ],
   "source": [
    "def chequeator(df_to_submit):\n",
    "    \"\"\"\n",
    "    Esta función se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
    "    \n",
    "    Si es así, se guardará el dataframe en un `csv` y estará listo para subir a Kaggle.\n",
    "    \n",
    "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
    "    \n",
    "    Si aún no:\n",
    "    - apaga tu ordenador, \n",
    "    - date una vuelta, \n",
    "    - enciendelo otra vez, \n",
    "    - abre este notebook y \n",
    "    - leelo todo de nuevo. \n",
    "    Todos nos merecemos una segunda oportunidad. También tú.\n",
    "    \"\"\"\n",
    "    if df_to_submit.shape == sample.shape:\n",
    "        if df_to_submit.columns.all() == sample.columns.all():\n",
    "            if df_to_submit.id.all() == sample.id.all():\n",
    "                print(\"You're ready to submit!\")\n",
    "                submission.to_csv(\"submission.csv\", index = False) #muy importante el index = False\n",
    "                urllib.request.urlretrieve(\"https://i.kym-cdn.com/photos/images/facebook/000/747/556/27a.jpg\", \"gfg.png\")     \n",
    "                img = Image.open(\"gfg.png\")\n",
    "                img.show()   \n",
    "            else:\n",
    "                print(\"Check the ids and try again\")\n",
    "        else:\n",
    "            print(\"Check the names of the columns and try again\")\n",
    "    else:\n",
    "        print(\"Check the number of rows and/or columns and try again\")\n",
    "        print(\"\\nMensaje secreto de Clara: No me puedo creer que después de todo este notebook hayas hecho algún cambio en las filas de `diamonds_test.csv`. Lloro.\")\n",
    "chequeator(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Almost-Pro way\n",
    "\n",
    "La forma pro es la que hace esto mismo y va recogiendo los errores de entrenamiento, de validación y tiene la capacidad de parar el proceso cuando se requiera además de guardar el modelo en local una vez terminado si es mejor que el que había anteriormente y de cargar el modelo anterior y seguir reentrenando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Create a pipeline\n",
    "\n",
    "# Le podemos poner cualquier clasificador. Irá cambiando según va probando pero necesita 1.\n",
    "# es posible ajustar los parámetros a probar con cada clasificador definiendolos en sus respectivos diccionarios\n",
    "pipe = Pipeline(steps=[('classifier', RandomForestClassifier())])\n",
    "to_test = np.arange(1, 10)\n",
    "# parámetros a probar con logisticRegression\n",
    "logistic_params = {\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__C': np.logspace(0, 4, 10)\n",
    "    }\n",
    "\n",
    "# parámetros a probar con RandomForestClassifier\n",
    "random_forest_params = {\n",
    "    'classifier': [RandomForestClassifier()],\n",
    "    'classifier__n_estimators': [10, 100, 1000],\n",
    "    'classifier__max_features': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "# parámetros a probar con SVC\n",
    "svm_params = {\n",
    "    'classifier': [svm.SVC()],\n",
    "    'classifier__kernel':('linear', 'rbf', 'sigmoid'), \n",
    "    'classifier__C':[0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "    'classifier__degree': to_test,\n",
    "    'classifier__coef0': [-10.,-1., 0., 0.1, 0.5, 1, 10, 100],\n",
    "    'classifier__gamma': ('scale', 'auto')\n",
    "    }\n",
    "\n",
    "# hypertuning \n",
    "# Create space of candidate learning algorithms and their hyperparameters\n",
    "search_space = [\n",
    "    logistic_params,\n",
    "    random_forest_params,\n",
    "    svm_params\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n############################\n\nbest estimator: SVC(C=0.5, coef0=-10.0, degree=1, kernel='linear')\n\n############################\n\nclf.best_params_ {'classifier': SVC(C=0.5, coef0=-10.0, degree=1, kernel='linear'), 'classifier__C': 0.5, 'classifier__coef0': -10.0, 'classifier__degree': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}\n\n############################\n\nclf.best_score 0.9916666666666666\nWall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "# Create grid search \n",
    "clf = GridSearchCV(estimator=pipe, param_grid=search_space, cv=cv, verbose=0, n_jobs=-1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# View best model\n",
    "separator = \"\\n############################\\n\"\n",
    "print(separator)\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\n",
    "print(separator)\n",
    "print(\"clf.best_params_\", clf.best_params_)\n",
    "print(separator)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf.best_score_)\n",
    "#SAVE MODEL\n",
    "# save the model to disk\n",
    "filename = 'finished_model.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + os.sep\n",
    "full_file_name = path + \"finished_model.sav\"\n",
    "loaded_model = pickle.load(open(full_file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "# Predict target vector\n",
    "best_model.score(X_test, y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "type(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Another way - No pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 0 \n",
    "0 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                    'gamma': [1e-3, 1e-4], \n",
    "                    'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], \n",
    "                    'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "######################################\n",
      "########## SCORE precision ########### \n",
      "######################################\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.986 (+/-0.016) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.983 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.983 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.974 (+/-0.012) for {'C': 1, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 10, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 100, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 1000, 'kernel': 'linear'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       1.00      0.99      0.99        93\n",
      "           4       1.00      1.00      1.00        76\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.99      1.00      0.99        78\n",
      "           8       1.00      0.98      0.99        92\n",
      "           9       0.99      0.99      0.99        92\n",
      "\n",
      "    accuracy                           0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n",
      "######################################\n",
      "########## SCORE recall ########### \n",
      "######################################\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.986 (+/-0.019) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.957 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.981 (+/-0.028) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.971 (+/-0.010) for {'C': 1, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 10, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 100, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 1000, 'kernel': 'linear'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       1.00      0.99      0.99        93\n",
      "           4       1.00      1.00      1.00        76\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.99      1.00      0.99        78\n",
      "           8       1.00      0.98      0.99        92\n",
      "           9       0.99      0.99      0.99        92\n",
      "\n",
      "    accuracy                           0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bar = \"######################################\"\n",
    "for score in scores:\n",
    "    print(bar + \"\\n########## SCORE \" + score + \" ########### \\n\" + bar)\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(estimator=SVC(), param_grid=tuned_parameters, scoring=str(score)+'_macro')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}